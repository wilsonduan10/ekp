## Overview
This folder includes all the calibration files that pertain to the use of EKI with LES data, which can be found here: https://data.caltech.edu/records/a59sz-z5n11. The data is split into different cfSites and months, marking the location of the data collected and the month it was collected at, respectively. The LES data consists of data mostly belonging to the unstable surface layer, hence we calibrate only b_m and b_h of the Businger function parameters.

![](../assets/LESdata.png)

## How to run
The files must be run as follows:
- First, make sure you are in the root of the repository in the terminal.
- Second, run the command: julia --project
- Third, instantiate all dependencies.
- Lastly, type the line: include("LES_Code/<`filename`>")

## Contents
The core files of this folder are `load_data.jl` and `physical_model.jl` â€“ `load_data.jl` loads in the cfSite data, and `physical_model.jl` represents the surface flux model. Aside from that, there exist files that use different observables to perform calibration, as well as files for data analysis and sensitivity analysis. 

### `load_data.jl`
This file defines a dataset struct that holds all of the data relevant for calibration, such as wind speed, specific humidity, and temperature at different timesteps and different heights. It also defines a function `create_dataframe`, which, when given a cfSite and month to retrieve data from, returns a dataframe populated with the data given from the file with the given cfSite and month. It contains an optional boolean argument extrapolate_surface, which allows the user to extrapolate the values of air density and total specific humidity at the surface in the case that it is not given by the dataset. Since the LES data does not provide these values, the extrapolate_surface parameter defaults to true.

### `physical_model.jl`
This file defines the model used in each of the calibration files. The model has the arguments: parameters, parameterTypes, data, universal function type, thermodynamic state type, and solving scheme. The parameterTypes allow the user to specify which stability function parameters they want to calibrate (such as a\_m, a\_h, b\_m, b\_h). The thermodynamic state type specifies which thermodynamic function to use when establishing the thermodynamic state, to be inputted into the `surface_conditions` function from SurfaceFluxes.jl. The solving scheme is either ValuesOnly, Fluxes, or FluxesAndFrictionVelocity, which specifies the type of information provided to `surface_conditions`. This function returns a matrix of surface information, with dimensions Z x T (height dimension x time dimension). The output of this function will be used by the calibration files, where there will be an observation map H defined, which takes in this matrix and provides the observable. 

There also exists the function `physical_model_profiles`, which instead of outputting a matrix of surface information, it predicts 3 profiles over time: wind speed, moisture, and potential temperature.

### `businger_calibration.jl`
This file is the primary calibration file, using LES metrics as the observable. It calibrates the parameters b\_m and b\_h, and generates plots that display the efficacy of the calibration. There are many variables that the user can experiment with to test different results: the cfSite and month for different LES data, the UF type, the thermodynamic function used, the input container to `surface_conditions`, and even the observable used. The default observable is ustar, but it can be changed easily to sensible heat flux, latent heat flux, and a few other measures so long as it exists in the dataset and the surface information returned by `physical_model`. Running this file, the images are generated in the images/businger_calibration folder, with a custom foldername depending on the cfSite and month used. It is notable that the observable is generally overpredicted by our surface flux model given theta\_true - see my final paper for more analysis. 

### `perfect_model.jl`
This file uses an artificially generated metric as the observable - it is generated by adding Gaussian distributed noise to the model truth. Otherwise, the calibration pipeline is identical to that of `businger_calibration.jl`, and it displays excellent results - it is able to quickly reduce the error between the predictions and the observations. However, we must note that while b\_m converges towards the true b\_m of 15, the b\_h does not converge towards the true b\_h of 9. This is due to the model's insensitivity towards the parameters b\_m, making calibration difficult. 

